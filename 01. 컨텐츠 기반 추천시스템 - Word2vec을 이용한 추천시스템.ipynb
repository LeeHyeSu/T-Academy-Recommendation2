{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컨텐츠 기반 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "✅ 통계기반의 방법 단점\n",
    "- 대규모 말뭉치를 다룰 때 메모리상의 문제가 발생 \n",
    "    - 높은 차원을 가짐 , 매우 sparse 한 형태의 데이터임 \n",
    "    - 예) 100만개의 문서를 다루는 경우 : 100만개의 문서에 등장한 모든 단어를 추출해야하고 \n",
    "      이때 단어의 수는 1문서당 새로운 단어가 10개면, 1000만개정도의 말뭉치가 형성됨.\n",
    "      즉, 100만 x 1000만의 매트릭스가 형성 \n",
    "- 한번에 학습 데이터 전체를 진행함 \n",
    "    - 큰 작업을 처리하기 어려움 \n",
    "    - GPU 와 같은 병렬처리를 기대하기 힘듬\n",
    "- 학습을 통해서 개선하기가 어려움\n",
    "\n",
    "✅ 추론기반의 방법 (Word2Vec) \n",
    "추론 : 주변 단어(맥락)이 주어졌을 때 “?”에 무슨 단어(중심단어)가 들어가는지를 추측하는 작업\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "✅ 정의 \n",
    "Word2Vec 은 단어간 유사도를 반영하여 단어를 벡터로 바꿔주는 임베딩 방법론. \n",
    "원-핫벡터 형태의 sparse matrix 이 가지는 단점을 해소하고자 저차원의 공간에 벡터로 매핑하는 것이 특징. \n",
    "Word2Vec 은 “비슷한 위치에 등장하는 단어들은 비슷한 의미를 가진다“ 라는 가정을 통해서 학습을 진행.\n",
    "저차원에 학습된 단어의 의미를 분산하여 표현하기에 단어 간 유사도를 계산.\n",
    "추천시스템에서는 단어를 구매 상품으로 바꿔서 구매한 패턴에 Word2Vec 을 적용해서 비슷한 상품을 찾을 수 있음\n",
    "\n",
    "✅ 알고리즘 \n",
    "CBOW : 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법. \n",
    "Skip-Gram : 중간에 있는 단어로 주변 단어들을 예측하는 방법.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec - CBOW\n",
    "> you [   ?   ] goodbye and I say hello.\n",
    "```\n",
    "1. One Hot Vector 형태의 입력값을 받는다. \n",
    "    -  you -> [say] 예측 \n",
    "    -  goodbye -> [say] 예측 \n",
    "    -  주변 단어 : 주변에 있는 단어 (you, goodbye) \n",
    "    -  중심 단어 : 중간에 있는 단어 (say) \n",
    "    -  윈도우 크기 : 주변을 몇 칸까지 볼 지에 대한 크기 (1), \n",
    "       만일, 윈도우 크기가 2이면 you, goodbye, and 를 통해서 [say]를 예측\n",
    "2. One Hot Vector 형태의 입력값을 W_in 과 곱\n",
    "3. Hidden state 의 값을 W_out 과 곱해서 Score 를 추출한다. \n",
    "4. Score 에 Softmax 를 취해서 각 단어가 나올 확률을 계산한다. \n",
    "5. 정답과 Cross Entropy Loss 를 계산\n",
    "6. 5에서 계산한 Loss 를 가지고 Backpropagation 과정을 통해서 Weight 를 업데이트\n",
    "7. 위의 과정을 다른 문맥에 대해서도 수행\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec – Skip-gram\n",
    "> [   ?   ] say [   ?   ] and I say hello.\n",
    "```\n",
    "1. One Hot Vector 형태의 입력값을 받는다. \n",
    "    -  say -> [you] 예측 \n",
    "    -  say -> [goodbye] 예측 \n",
    "    -  주변 단어 : 주변에 있는 단어 (you, goodbye) \n",
    "    -  중심 단어 : 중간에 있는 단어 (say) \n",
    "    -  윈도우 크기 : 주변을 몇 칸까지 볼 지에 대한 크기 (1), \n",
    "       만일, 윈도우 크기가 2이면 say 를 통해 [you], [goodbye], [and]를 예측\n",
    "2. One Hot Vector 형태의 입력값을 W_in 과 곱\n",
    "3. Hidden state 의 값을 W_out 과 곱해서 Score 를 추출한다. \n",
    "4. Score 에 Softmax 를 취해서 각 단어가 나올 확률을 계산한다. \n",
    "5. 정답과 Cross Entropy Loss 를 계산\n",
    "    - 한 번에 업데이트를 진행\n",
    "6. 5에서 계산한 Loss 를 가지고 Backpropagation 과정을 통해서 Weight 를 업데이트\n",
    "    - 두 개의 Answer 에 대해서 오차를 더함\n",
    "7. 위의 과정을 다른 문맥에 대해서도 수행\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "✅ 장점\n",
    "- 협업필터링은 다른 사용자들의 평점이 필요한 반면에, 자신의 평점만을 가지고 추천시스템을 만들 수 있음 \n",
    "- item 의 feature 를 통해서 추천을 하기에 추천이 된 이유를 설명하기 용이함 \n",
    "- 사용자가 평점을 매기지 않은 새로운 item 이 들어올 경우에도 추천이 가능함\n",
    "\n",
    "✅ 단점\n",
    "- item 의 feature 을 추출해야 하고 이를 통해서 추천하기때문에 제대로 feature 을 추출하지 못하면 정확도가 낮음. 그렇기에 Domain Knowledge 가 분석시에 필요할 수도 있음 \n",
    "- 기존의 item 과 유사한 item 위주로만 추천하기에 새로운 장르의 item 을 추천하기 어려움 \n",
    "- 새로운 사용자에 대해서 충분한 평점이 쌓이기 전까지는 추천하기 힘듬\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:32.884625Z",
     "start_time": "2021-06-11T06:07:25.774780Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:32.977650Z",
     "start_time": "2021-06-11T06:07:32.887619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv('data/ratings.csv', low_memory=False)\n",
    "movie.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:33.022537Z",
     "start_time": "2021-06-11T06:07:32.980622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>383</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>789652009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>789652009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>383</td>\n",
       "      <td>1079</td>\n",
       "      <td>3.0</td>\n",
       "      <td>789652009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>409</td>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828212412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>409</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "      <td>828212412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0     383       21     3.0  789652009\n",
       "1     383       47     5.0  789652009\n",
       "2     383     1079     3.0  789652009\n",
       "3     409       21     5.0  828212412\n",
       "4     409       25     4.0  828212412"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = movie.sort_values(by='timestamp', ascending=True).reset_index(drop=True)\n",
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:33.740746Z",
     "start_time": "2021-06-11T06:07:33.024505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "\n",
       "                               homepage    id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story   862  tt0114709                en   \n",
       "1                                   NaN  8844  tt0113497                en   \n",
       "\n",
       "  original_title                                           overview  ...  \\\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1        Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "\n",
       "                                     tagline      title  video vote_average  \\\n",
       "0                                        NaN  Toy Story  False          7.7   \n",
       "1  Roll the dice and unleash the excitement!    Jumanji  False          6.9   \n",
       "\n",
       "  vote_count  \n",
       "0     5415.0  \n",
       "1     2413.0  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영화의 Metadata를 불러와서 movieID에 맞는 TITLE을 구해줍니다. \n",
    "meta = pd.read_csv('data/movies_metadata.csv', low_memory=False)\n",
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:33.755710Z",
     "start_time": "2021-06-11T06:07:33.743712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
       "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
       "       'vote_average', 'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:33.956848Z",
     "start_time": "2021-06-11T06:07:33.757673Z"
    }
   },
   "outputs": [],
   "source": [
    "meta = meta.rename(columns={'id':'movieId'})\n",
    "movie['movieId'] = movie['movieId'].astype(str)\n",
    "meta['movieId'] = meta['movieId'].astype(str)\n",
    "\n",
    "movie = pd.merge(movie, meta[['movieId', 'original_title']], how='left', on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:34.002817Z",
     "start_time": "2021-06-11T06:07:33.958809Z"
    }
   },
   "outputs": [],
   "source": [
    "movie = movie[movie['original_title'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:34.095541Z",
     "start_time": "2021-06-11T06:07:34.004778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Jay and Silent Bob Strike Back, Vivement dima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Terminator 3: Rise of the Machines, The Conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[300, The Killing, Shortbus, Finding Neverland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[David, The Wedding Planner, Casablanca, Sleep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Gleaming the Cube, Cool Hand Luke, Hidalgo, U...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   unique\n",
       "userId                                                   \n",
       "1       [Jay and Silent Bob Strike Back, Vivement dima...\n",
       "2       [Terminator 3: Rise of the Machines, The Conve...\n",
       "3       [300, The Killing, Shortbus, Finding Neverland...\n",
       "4       [David, The Wedding Planner, Casablanca, Sleep...\n",
       "5       [Gleaming the Cube, Cool Hand Luke, Hidalgo, U..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = movie.groupby(['userId'])['original_title'].agg({'unique'})\n",
    "agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:34.111500Z",
     "start_time": "2021-06-11T06:07:34.098533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Endless Summer', 'Jarhead', '彼女の想いで', ...,\n",
       "       'The Lonedale Operator', 'Violeta se fue a los cielos',\n",
       "       'To Kill a Priest'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie['original_title'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:34.141418Z",
     "start_time": "2021-06-11T06:07:34.114492Z"
    }
   },
   "outputs": [],
   "source": [
    "# int형식은 Word2vec에서 학습이 안되므로 string으로 변경해줍니다. \n",
    "sentence = []\n",
    "for user_sentence in agg['unique'].values:\n",
    "    sentence.append(list(map(str, user_sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:53.977002Z",
     "start_time": "2021-06-11T06:07:34.143425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2vec의 학습을 진행해줍니다. \n",
    "from gensim.models import Word2Vec\n",
    "embedding_model = Word2Vec(sentence, vector_size=20, window = 5, \n",
    "                           min_count=1, workers=4, epochs=200, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:54.052802Z",
     "start_time": "2021-06-11T06:07:53.979995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Snow Cake', 0.8682476282119751),\n",
       " ('Face/Off', 0.7570157051086426),\n",
       " ('Blow', 0.752019464969635),\n",
       " (\"L'Aile ou la Cuisse\", 0.749976396560669),\n",
       " ('Star Trek: Nemesis', 0.748651385307312),\n",
       " ('Domicile Conjugal', 0.7416670918464661),\n",
       " ('Heavenly Creatures', 0.7391387820243835),\n",
       " ('Sunrise: A Song of Two Humans', 0.7389362454414368),\n",
       " ('Rumor Has It...', 0.7314111590385437),\n",
       " ('Conquest of the Planet of the Apes', 0.7279210090637207)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.wv.most_similar(positive=['Spider-Man 2'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec 적용\n",
    "![image](https://user-images.githubusercontent.com/37262132/121563570-7e01a500-ca55-11eb-89a9-003d6ca55aa1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:54.083717Z",
     "start_time": "2021-06-11T06:07:54.063770Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:07:54.877713Z",
     "start_time": "2021-06-11T06:07:54.085712Z"
    }
   },
   "outputs": [],
   "source": [
    "meta = pd.read_csv('data/movies_metadata.csv', low_memory=False)\n",
    "meta = meta[meta['original_title'].notnull()].reset_index(drop=True)\n",
    "meta = meta[meta['overview'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:08:33.007078Z",
     "start_time": "2021-06-11T06:07:54.880672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7326121c53d14470abf762fb1864170c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=44512.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "overview = []\n",
    "for words in tqdm(meta['overview']):\n",
    "    word_tokens = word_tokenize(words)\n",
    "    sentence = re.sub('[^A-Za-z0-9]+', ' ', str(word_tokens))\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence_tokens = word_tokenize(sentence)\n",
    "    result = ''\n",
    "    for token in sentence_tokens: \n",
    "        if token not in stop_words:\n",
    "            result += ' ' + token \n",
    "    result = result.strip().lower()\n",
    "    overview.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:08:33.023035Z",
     "start_time": "2021-06-11T06:08:33.009073Z"
    }
   },
   "outputs": [],
   "source": [
    "meta['pre_overview'] = overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:08:33.053953Z",
     "start_time": "2021-06-11T06:08:33.025030Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_vectorizer = doc2vec.Doc2Vec(\n",
    "    dm = 0,\n",
    "    dbow_words = 1,\n",
    "    window = 10,\n",
    "    vector_size = 100,\n",
    "    alpha = 0.025,\n",
    "    seed = 1234,\n",
    "    min_count = 5,    \n",
    "    min_alpha = 0.025,\n",
    "    workers = 4,\n",
    "    hs = 1,\n",
    "    negative = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:08:33.331211Z",
     "start_time": "2021-06-11T06:08:33.061931Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "agg = meta[['id', 'original_title', 'pre_overview']]\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "tagged_train_docs = [TaggedDocument((c), [d]) for d, c in agg[['original_title', 'pre_overview']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:08:35.109706Z",
     "start_time": "2021-06-11T06:08:33.333207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n10,hs,w10,mc5,s0.001,t4)\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:25:02.810505Z",
     "start_time": "2021-06-11T06:08:35.111688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a542685405415eb2e31667d2e3c28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "During Time: 987.6918349266052\n"
     ]
    }
   ],
   "source": [
    "# 벡터 문서 학습\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "for epoch in tqdm(range(5)):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.epochs)\n",
    "    doc_vectorizer.alpha -= 0.002\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha \n",
    "\n",
    "end = time()\n",
    "print(f\"During Time: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:25:02.841933Z",
     "start_time": "2021-06-11T06:25:02.812499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children in the Surf at Coney Island', 0.7353575229644775),\n",
       " ('Letzte Worte', 0.725882351398468),\n",
       " ('It Stains the Sands Red', 0.6859925985336304),\n",
       " ('McLaren', 0.6718501448631287),\n",
       " ('По следам бременских музыкантов', 0.6662031412124634),\n",
       " ('Skazka o Poteryannom Vremeni', 0.664352536201477),\n",
       " ('Kader', 0.6596434712409973),\n",
       " ('Wszyscy jesteśmy Chrystusami', 0.6588553786277771),\n",
       " ('Przechodzien', 0.6580846309661865),\n",
       " ('エクスマキナ', 0.65656977891922),\n",
       " ('Dying to Belong', 0.655059278011322),\n",
       " ('Begegnung mit Fritz Lang', 0.6500876545906067),\n",
       " ('La moutarde me monte au nez', 0.6462430953979492),\n",
       " ('El vendedor de humo', 0.6350132822990417),\n",
       " ('Особенности национальной политики', 0.6266170144081116),\n",
       " ('Live Forever as You Are Now with Alan Resnick', 0.6242215633392334),\n",
       " ('Der Sandmann', 0.6195182800292969),\n",
       " ('Milk Money', 0.6173915863037109),\n",
       " ('Stryapukha', 0.6121023893356323),\n",
       " ('Kaos', 0.5985434651374817)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.docvecs.most_similar('Toy Story', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T06:25:02.857888Z",
     "start_time": "2021-06-11T06:25:02.843927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Great Ecstasy of Robert Carmichael', 0.738102376461029),\n",
       " ('Handsome Harry', 0.7155303359031677),\n",
       " ('Der Räuber', 0.7069940567016602),\n",
       " ('Torch Song', 0.682845950126648),\n",
       " ('Classe tous risques', 0.6413491368293762),\n",
       " ('The Prizefighter and the Lady', 0.6199315190315247),\n",
       " ('Tribute', 0.6171056032180786),\n",
       " ('Blood River', 0.6087848544120789),\n",
       " ('Paternity', 0.6048902273178101),\n",
       " ('Three Comrades', 0.6044132113456726),\n",
       " ('Just Like Us', 0.6027846336364746),\n",
       " ('Steam', 0.602361798286438),\n",
       " ('1990: I guerrieri del Bronx', 0.5979241728782654),\n",
       " ('Kasaba', 0.597663164138794),\n",
       " ('The Librarian: Quest for the Spear', 0.5938440561294556),\n",
       " ('Glorious 39', 0.591773509979248),\n",
       " ('My Beautiful Dacia', 0.5884438157081604),\n",
       " ('Mirrors 2', 0.5798097848892212),\n",
       " ('Skupljači perja', 0.573143482208252),\n",
       " ('Run of the Arrow', 0.5725336670875549)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.docvecs.most_similar('Harry Potter and the Deathly Hallows: Part 1', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
